import pandas as pd
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.svm import LinearSVC
from sklearn.pipeline import Pipeline
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report
import joblib

from indicnlp.normalize.indic_normalize import IndicNormalizerFactory
from indicnlp.tokenize.indic_tokenize import trivial_tokenize

# -----------------
# Dictionaries
# -----------------
marathi_dictionary = {
    # Greetings & common
    "рд╣рд╛рдп": "рдирдорд╕реНрдХрд╛рд░",
    "рдмрд╛рдп": "рдкреБрдиреНрд╣рд╛ рднреЗрдЯреВ",
    "рдереЕрдВрдХреНрдпреВ": "рдзрдиреНрдпрд╡рд╛рдж",
    "рдереЕрдВрдХреНрд╕": "рдордирдГрдкреВрд░реНрд╡рдХ рдЖрднрд╛рд░",
    "рдХрд╛рдп рдЪрд╛рд▓рд▓рдВрдп?": "рд╕рдзреНрдпрд╛ рдХрд╛рдп рд╕реБрд░реВ рдЖрд╣реЗ?",
    "рдХрд╕рд╛ рдЖрд╣реЗрд╕?": "рдЖрдкрдг рдХрд╕реЗ рдЖрд╣рд╛рдд?",
    "рдХрд╢реА рдЖрд╣реЗрд╕?": "рдЖрдкрдг рдХрд╢рд╛ рдЖрд╣рд╛рдд?",
    "рдХрд╕рдВ рдХрд╛рдп?": "рдЖрдкрдг рдХрд╕реЗ рдЖрд╣рд╛рдд?",
    "рдХреБрдардВ рдЬрд╛рддреЛрд╕?": "рдЖрдкрдг рдХреБрдареЗ рдЬрд╛рдд рдЖрд╣рд╛рдд?",
    "рднреЗрдЯреВ рдирдВрддрд░.": "рдЖрдкрдг рдирдВрддрд░ рднреЗрдЯреВрдпрд╛.",
    "рдЪрд▓ рднреЗрдЯреВ рдирдВрддрд░.": "рдЪрд▓рд╛ рдЖрдкрдг рдирдВрддрд░ рднреЗрдЯреВрдпрд╛.",
    "рдЪрд▓ рдирд┐рдШреВрдпрд╛.": "рдЪрд▓рд╛ рдЖрдкрдг рдирд┐рдШреВрдпрд╛.",

    # Actions
    "рдЪрд▓": "рдЪрд▓рд╛",
    "рдпреЗ": "рдпрд╛",
    "рдмрд╕": "рдмрд╕реВрди рдШреНрдпрд╛",
    "рдерд╛рдВрдм": "рдХреГрдкрдпрд╛ рдерд╛рдВрдмрд╛",
    "рдерд╛рдВрдм рдЬрд░рд╛!": "рдХреГрдкрдпрд╛ рдереЛрдбрд╛ рд╡реЗрд│ рдерд╛рдВрдмрд╛.",
    "рдереЛрдбрдВ рдерд╛рдВрдм.": "рдХреГрдкрдпрд╛ рдереЛрдбрд╛ рд╡реЗрд│ рдерд╛рдВрдмрд╛.",
    "рдЦрд╛рдК": "рднреЛрдЬрди рдХрд░рд╛",
    "рдЭреЛрдк": "рд╡рд┐рд╢реНрд░рд╛рдВрддреА рдШреНрдпрд╛",
    "рдЙрда": "рдЙрдард╛",
    "рдмрдШ": "рдкрд╣рд╛",
    "рдРрдХ": "рдХреГрдкрдпрд╛ рдРрдХрд╛",
    "рд╕рд╛рдВрдЧ": "рдХреГрдкрдпрд╛ рд╕рд╛рдВрдЧрд╛",
    "рдХрд░": "рдХреГрдкрдпрд╛ рдХрд░рд╛",

    # Negatives
    "рдирдХреЛ": "рдирдХреЛ рдЖрд╣реЗ",
    "рдирдХреЛ рдирд╛ рдЕрд╕рдВ рдХрд░реВрд╕.": "рдХреГрдкрдпрд╛ рдЕрд╕реЗ рдХрд░реВ рдирдХрд╛.",
    "рдХрд░реВ рдирдХреЛ": "рдХреГрдкрдпрд╛ рдХрд░реВ рдирдХрд╛",
    "рдЪрд▓ рдирдХреЛ": "рдХреГрдкрдпрд╛ рдЬрд╛рдК рдирдХрд╛",
    "рдирд╛рд╣реА": "рдирд╛рд╣реА рдЖрд╣реЗ",
    "рдХрд╛рд╣реА рдирд╛рд╣реА": "рдХрд╛рд╣реАрд╣реА рдЙрдкрд▓рдмреНрдз рдирд╛рд╣реА",

    # Emotions / slang
    "рдорд╕реНрдд": "рдЙрддреНрддрдо",
    "рдЭрдХрд╛рд╕": "рдЙрддреНрдХреГрд╖реНрдЯ",
    "рдзрдореНрдорд╛рд▓": "рдЖрдирдВрджрджрд╛рдпреА",
    "рднрд╛рд░реА": "рдЕрддреНрдпрдВрдд рдЪрд╛рдВрдЧрд▓реЗ",
    "рдЬрдмрд░реА": "рдЕрддрд┐рд╢рдп рдЙрддреНрдХреГрд╖реНрдЯ",
    "рд╣реЗ рдорд╕реНрдд рдЖрд╣реЗ!": "рд╣реЗ рдЕрддрд┐рд╢рдп рдЙрддреНрдХреГрд╖реНрдЯ рдЖрд╣реЗ!",
    "рд╣рд╛ рднрд╛рд░реА рдЖрд╣реЗ!": "рд╣рд╛ рдЕрддреНрдпрдВрдд рдЪрд╛рдВрдЧрд▓рд╛ рдЖрд╣реЗ!",

    # Personal / pronouns
    "рддреБ рдХрд╛рдп рдХрд░рддреЛрд╕?": "рдЖрдкрдг рдХрд╛рдп рдХрд░рдд рдЖрд╣рд╛рдд?",
    "рддреВ рдХреБрдареЗ рдЬрд╛рддреЛрдп?": "рдЖрдкрдг рдХреБрдареЗ рдЬрд╛рдд рдЖрд╣рд╛рдд?",
    "рддреВ рдареАрдХ рдЖрд╣реЗрд╕ рдХрд╛?": "рдЖрдкрд▓реА рддрдмреНрдпреЗрдд рдареАрдХ рдЖрд╣реЗ рдХрд╛?",
    "рддреБрд▓рд╛ рдорд╛рд╣рд┐рдд рдЖрд╣реЗ рдХрд╛?": "рдЖрдкрд▓реНрдпрд╛рд▓рд╛ рдорд╛рд╣рд┐рддреА рдЖрд╣реЗ рдХрд╛?",
    "рдХрд╛рдп рдЭрд╛рд▓рдВ рд░реЗ рддреБрд▓рд╛?": "рдЖрдкрд▓реНрдпрд╛рд▓рд╛ рдХрд╛рдп рдЭрд╛рд▓реЗ рдЖрд╣реЗ?",
    "рдорд╛рдЭреНрдпрд╛рдХрдбрдВ рдкреИрд╕реЗ рдирд╛рд╣реАрдд.": "рдорд╛рдЭреНрдпрд╛рдХрдбреЗ рдкреИрд╕реЗ рдЙрдкрд▓рдмреНрдз рдирд╛рд╣реАрдд.",
    "рдорд▓рд╛ рднреЗрдЯрд╛рдпрдЪрдВ рдЖрд╣реЗ.": "рдорд▓рд╛ рдЖрдкрд▓реНрдпрд╛рд▓рд╛ рднреЗрдЯрд╛рдпрдЪреЗ рдЖрд╣реЗ.",
    "рдорд╛рдЭрдВ рдХрд╛рдо рдЭрд╛рд▓рдВ.": "рдорд╛рдЭрдВ рдХрд╛рдо рдкреВрд░реНрдг рдЭрд╛рд▓рдВ рдЖрд╣реЗ.",
    "рдорд╛рдЭреА рдЪреВрдХ рдЭрд╛рд▓реА.": "рдорд╛рдЭреНрдпрд╛рдХрдбреВрди рдЪреВрдХ рдЭрд╛рд▓реА рдЖрд╣реЗ.",
    "рдорд▓рд╛ рдЭреЛрдк рдпреЗрддреЗрдп.": "рдорд▓рд╛ рдЭреЛрдк рдпреЗрдд рдЖрд╣реЗ.",
    "рдорд▓рд╛ рд╕рдордЬрд▓рдВ рдирд╛рд╣реА.": "рдорд▓рд╛ рд╕рдордЬрд▓реЗ рдирд╛рд╣реА.",
    "рдорд▓рд╛ рдорд╛рд╣рд┐рддреА рдирд╛рд╣реА.": "рдорд╛рдЭреНрдпрд╛ рдорд╛рд╣рд┐рддреАрдиреБрд╕рд╛рд░ рдорд▓рд╛ рдорд╛рд╣рд┐рддреА рдирд╛рд╣реА.",
    "рдорд▓рд╛ рдХрд╛рд╣реА рд╡рд┐рдЪрд╛рд░рд╛рдпрдЪрдВ рдЖрд╣реЗ.": "рдорд▓рд╛ рдХрд╛рд╣реА рд╡рд┐рдЪрд╛рд░рд╛рдпрдЪреЗ рдЖрд╣реЗ.",
    "рдорд▓рд╛ рд╡реЗрд│ рдирд╛рд╣реА.": "рдорд╛рдЭреНрдпрд╛рдХрдбреЗ рд╡реЗрд│ рдирд╛рд╣реА.",
    "рдорд▓рд╛ рд╣рд╡рдпрдВ!": "рдорд▓рд╛ рддреЗ рд╣рд╡реЗ рдЖрд╣реЗ.",

    # Polite apologies & requests
    "рдорд╛рдл рдХрд░.": "рдХреГрдкрдпрд╛ рдорд▓рд╛ рдХреНрд╖рдорд╛ рдХрд░рд╛.",
    "рдорд╛рдл рдХрд░ рдирд╛!": "рдХреГрдкрдпрд╛ рдорд▓рд╛ рдХреНрд╖рдорд╛ рдХрд░рд╛.",
    "рдорд╛рдл рдХрд░рд╢реАрд▓ рдХрд╛?": "рдХреГрдкрдпрд╛ рдорд▓рд╛ рдХреНрд╖рдорд╛ рдХрд░рд╛рд▓ рдХрд╛?",
    "рд╕рд╛рдВрдЧ рдирд╛ рдорд▓рд╛!": "рдХреГрдкрдпрд╛ рдорд▓рд╛ рд╕рд╛рдВрдЧрд╛.",

    # Questions
    "рдХрдзреА рдпреЗрдгрд╛рд░?": "рдЖрдкрдг рдХрдзреА рдпреЗрдгрд╛рд░ рдЖрд╣рд╛рдд?",
    "рдХрд╛рдп рдЭрд╛рд▓рдВ?": "рдЖрдкрд▓реНрдпрд╛рд▓рд╛ рдХрд╛рдп рдЕрдбрдЪрдг рдЖрд▓реА рдЖрд╣реЗ?",
    "рдХрд╛рдп рд░реЗ рдордЬрд╛!": "рд╣реЗ рдЦреВрдк рдЖрдирдВрджрджрд╛рдпрдХ рдЖрд╣реЗ!",
    "рдкрд╛рд╣рд┐рд▓рдВ рдХрд╛?": "рдЖрдкрдг рдкрд╛рд╣рд┐рд▓реЗ рдХрд╛?",
    "рдмрдШрд┐рддрд▓рдВрд╕ рдХрд╛?": "рдЖрдкрдг рдкрд╛рд╣рд┐рд▓реЗ рдХрд╛?",
    "рд╕реБрдЯреНрдЯреА рдЖрд╣реЗ рдХрд╛?": "рдЖрдЬ рд╕реБрдЯреНрдЯреА рдЖрд╣реЗ рдХрд╛?",
    "рд╣реЗ рдЦрд░рдВ рдЖрд╣реЗ рдХрд╛?": "рд╣реЗ рд╕рддреНрдп рдЖрд╣реЗ рдХрд╛?",
    "рд╣реЛ рдХрд╛?": "рдЦрд░реЛрдЦрд░ рддрд╕реЗ рдЖрд╣реЗ рдХрд╛?",
    "рд╣реЛ рдорд▓рд╛ рдорд╛рд╣рд┐рдд рдЖрд╣реЗ.": "рд╣реЛрдп, рдорд▓рд╛ рдорд╛рд╣рд┐рддреА рдЖрд╣реЗ.",
    "рд╣реЛ рд╣реЛ!": "рд╣реЛрдп.",
    "рдЕрдЬреВрди рд╡реЗрд│ рд▓рд╛рдЧреЗрд▓ рдХрд╛?": "рдереЛрдбрд╛ рдЕрдзрд┐рдХ рд╡реЗрд│ рд▓рд╛рдЧреЗрд▓ рдХрд╛?",
    "рдЖрдкрдг рднреЗрдЯрд▓реЛ рдХрд╛ рдкреВрд░реНрд╡реА?": "рдЖрдкрдг рдкреВрд░реНрд╡реА рдХрдзреА рднреЗрдЯрд▓реЛ рдЖрд╣реЛрдд рдХрд╛?",
}

# Synonym-level replacements (used inside sentences)
synonym_dict = {
    "рд░реЗ": "рдорд╣реЛрджрдп",
    "рдЕрдЧрдВ": "рдорд╣реЛрджрдпрд╛",
    "рд╣рд╛рдп": "рдЖрд╣реЗ",
    "рд╣реЛ": "рд╣реЛрдп",
    "рдХрд╛рдп": "рдХрд╛рдп рдЖрд╣реЗ",
    "рдЭрд╛рд▓рдВ": "рдЭрд╛рд▓реЗ рдЖрд╣реЗ",
    "рдЭрд╛рд▓рдВрдп": "рдЭрд╛рд▓реЗ рдЖрд╣реЗ",
    "рдорд╛рд╣рд┐рдд": "рдорд╛рд╣рд┐рддреА",
    "рдЪрд▓": "рдЪрд▓рд╛",
    "рдмрдШ": "рдкрд╣рд╛",
    "рд╕рд╛рдВрдЧ": "рдХреГрдкрдпрд╛ рд╕рд╛рдВрдЧрд╛",
    "рдирд╛": "рдХреГрдкрдпрд╛",
    "рдорд▓рд╛": "рдорд╛рдЭреНрдпрд╛рд╕рд╛рдареА",
    "рдирдВрддрд░": "рдкрд╢реНрдЪрд╛рдд",
    "рднреЗрдЯреВ": "рднреЗрдЯреВрдпрд╛",
}


# ---------
# Cleaning
# ---------
PUNCT = '!"#$%&\'()*+,-./:;<=>?@[\\]^_`{|}~редтАжтАУтАФ'
TRANS = str.maketrans({c: " " for c in PUNCT})

def normalize_synonyms(text: str) -> str:
    words = text.split()
    return ' '.join(synonym_dict.get(w, w) for w in words)

factory = IndicNormalizerFactory()
normalizer = factory.get_normalizer("mr")

def marathi_lemmatize(text: str) -> str:
    text = normalizer.normalize(text)
    # tokenization keeps Unicode intact
    return ' '.join(trivial_tokenize(text, lang="mr"))

def preprocess_sentence(sentence: str) -> str:
    # dictionary replacement
    if sentence in marathi_dictionary:
        sentence = marathi_dictionary[sentence]
    # keep Devanagari, only strip punctuation
    sentence = sentence.translate(TRANS)
    sentence = sentence.strip()
    # (lower has no effect for Devanagari, but harmless)
    sentence = sentence.lower()
    sentence = marathi_lemmatize(sentence)
    sentence = normalize_synonyms(sentence)
    # IMPORTANT: no naive stemming (kept OFF to preserve matras)
    return sentence

# -------------
# Load & prep
# -------------
df = pd.read_csv(r"C:/marathi-formalizer/data/marathi_dataset_500.csv")
df["input_processed"]  = df["informal"].apply(preprocess_sentence)
df["target_processed"] = df["formal"].apply(preprocess_sentence)

X_train, X_test, y_train, y_test = train_test_split(
    df["input_processed"], df["target_processed"], test_size=0.2, random_state=42
)

# -------------
# Model (char n-grams + LinearSVC)
# -------------
model = Pipeline([
    ("tfidf", TfidfVectorizer(analyzer="char_wb", ngram_range=(3,6), min_df=1)),
    ("clf", LinearSVC())
])

model.fit(X_train, y_train)

preds = model.predict(X_test)
print("\nЁЯз╛ Classification Report:")
print(classification_report(y_test, preds))

joblib.dump(model, "marathi_formalizer.pkl")
print("тЬЕ Model saved as marathi_formalizer.pkl")
